# -*- coding: utf-8 -*-
"""phonetics.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1uXFwQWkc6c2-D22x3uVvf5SkQO4JKPZ5

# Práctica 1
"""

import requests as r
from collections import defaultdict
import math

lang_codes = {
  "ar": "Arabic (Modern Standard)",
  "de": "German",
  "en_UK": "English (Received Pronunciation)",
  "en_US": "English (General American)",
  "eo": "Esperanto",
  "es_ES": "Spanish (Spain)",
  "es_MX": "Spanish (Mexico)",
  "fa": "Persian",
  "fi": "Finnish",
  "fr_FR": "French (France)",
  "fr_QC": "French (Québec)",
  "is": "Icelandic",
  "ja": "Japanese",
  "jam": "Jamaican Creole",
  "km": "Khmer",
  "ko": "Korean",
  "ma": "Malay (Malaysian and Indonesian)",
  "nb": "Norwegian Bokmål",
  "nl": "Dutch",
  "or": "Odia",
  "ro": "Romanian",
  "sv": "Swedish",
  "sw": "Swahili",
  "tts": "Isan",
  "vi_C": "Vietnamese (Central)",
  "vi_N": "Vietnamese (Northern)",
  "vi_S": "Vietnamese (Southern)",
  "yue": "Cantonese",
  "zh": "Mandarin"
}
iso_lang_codes = list(lang_codes.keys())

def response_to_dict(ipa_list: list) -> dict:
    """Parse to dict the list of word-IPA

    Each element of text hae the format:
    [WORD][TAB][IPA]

    Parameters
    ----------
    ipa_list: list
        List with each row of ipa-dict raw dataset file

    Returns
    -------
    dict:
        A dictionary with the word as key and the phonetic
        representation as value
    """
    result = {}
    for item in ipa_list:
        item_list = item.split("\t")
        result[item_list[0]] = item_list[1]
    return result

def get_ipa_dict(iso_lang: str) -> dict:
    """Get ipa-dict file from Github

    Parameters:
    -----------
    iso_lang:
        Language as iso code

    Results:
    --------
    dict:
        Dictionary with words as keys and phonetic representation
        as values for a given lang code
    """
    response = r.get(f"https://raw.githubusercontent.com/open-dict-data/ipa-dict/master/data/{iso_lang}.txt")
    raw_data = response.text.split("\n")
    return response_to_dict(raw_data[:-1])

def get_ipa_transcriptions(word: str, dataset: dict) -> list[str]:
    """Search for word in a given dataset of IPA phonetics

    Given a word this function return the IPA transcriptions

    Parameters:
    -----------
    word: str
        A word to search in the dataset
    dataset: dict
        A dataset for a given language code
    Returns
      the word phonetic in the given lenguage
    -------
    """
    return dataset.get(word.lower(), "NOT FOUND").split(', ')

def get_similar(word: str, dataset: dict) -> list[str]:
  """
    Search for similar words in the given dataset
    Parameters:
    -----------
    word: str
        A word to search similar words in the dataset
    dataset: dict
        A dataset for a given language code
    Returns
      the similar words
    -------
  """
  similar = []

  len_subword= math.ceil((len(word)/2))+1
  first_subw = word[:len_subword] #obtenemos las subcadenas que se van a buscar
  second_subw = word[-len_subword:]

  for w in dataset: #buscamos en todo el dataset
    if (first_subw in w or second_subw in w) and len(w) <= len(word): # el <= para que no salga cosas muy raras
      similar.append(w)

  return similar[6:]

downloaded_datasets = {}

"""### Buscador de oraciones y palabras"""

print("Representación fonética de palabras/oraciones")

print(f"Lenguas disponibles: {(iso_lang_codes)}")

lang = input("lang>> ")


while lang:
    if lang in iso_lang_codes:
      if lang in list(downloaded_datasets.keys()):
        print(f"Lenguaje seleccionado: {lang_codes[lang]}")
      else:
        print("Corpus no encontrado. Descargando...")
        downloaded_datasets[lang] = get_ipa_dict(lang)

      sub_dataset = downloaded_datasets[lang]
      query = input(f"  [{lang}]palabra/oración>> ")

      while query:
        result = []
        not_found = []
        for q in query.split(" "):
          res = get_ipa_transcriptions(q, sub_dataset)
          if "NOT FOUND" in res:
            result.append("".join(["_" for i in q]))
            not_found.append(q)
          else:
            result.append("|".join(res))

        print(f"\t\t{query} -> {' '.join(result)}")
        if len(not_found) > 0:
          print(f"\t\tNo se encontró: {', '.join(not_found)}")
          for wrd in not_found:
            similar_words = get_similar(wrd.lower(), sub_dataset)
            if len(similar_words) == 0:
              print("\t\t\tTampoco se encontraron palabras parecidas")
            else:
              print(f"\t\t\tPalabras parecidas para {wrd}:")
              for s in similar_words:
                print(f"\t\t\t - {s}")

        query = input(f"  [{lang}]palabra/oración>> ")

    else:
      print('opción inválida')
    lang = input("lang>> ")

print("Adios 👋🏼")

