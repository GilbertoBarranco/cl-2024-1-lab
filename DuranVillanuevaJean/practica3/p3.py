if __name__ == "__main__":
  # -*- coding: utf-8 -*-
  """p2_v2_(CRFs).ipynb

  Automatically generated by Colaboratory.

  Original file is located at
      https://colab.research.google.com/drive/1ofwterNURYtAkmQ2DuLp3IepwQfDfw8U
  #---------------------------------------------------------------------------#


  # Practica

  ## Instalando dependencias e importano biliotecas
  """

  #pip install -U sklearn-crfsuite

  from sklearn_crfsuite import CRF #modelo
  from sklearn.model_selection import train_test_split #para partir datos en train y test

  """## Trayendo datos

  ### Declaramos el corpus y lo traemos.
  """

  raw_corpus = []
  path = './corpus_otomi'

  import ast
  encoding = 'utf-8'

  with open(path, 'r',encoding=encoding) as file:
    # Iterate over each line in the file
    for line in file:
      try:
        raw_corpus.append(eval(line)) # Use eval() to convert the line into a Python list
        #print(raw_corpus)
      except SyntaxError:
        print(f"Skipping line: {line.strip()} (not a valid Python list)")

  """Observamos su estructura y el tamaño de este"""

  """
  oracion:

  [
    [['n', 'psd'], ['dó', '1.cpl'], ['phu̱di', 'stem'], 'v'],                         #palabra <----
    [['dó', '1.cpl'], ['pe̱phí', 'stem'], 'v'],                                       #palabra
    [['bi', '3.cpl'], ['t', 'lig'], ["'u̱n", 'stem'], ['gí', '1.obj'], 'v'],          #palabra
    [['bi', '3.cpl'], ['mähtratá', 'stem'], ['gí', '1.obj'], 'v'],                   #palabra
    [['ko', 'stem'], 'obl'],                                                         #palabra
    [['chíkóhté', 'stem'], 'obl']                                                    #palabra
  ]
  """
  """
    [['n', 'psd'], ['dó', '1.cpl'], ['phu̱di', 'stem'], 'v']  ----- la palabra es -----> n-dó-phu̱di
                                                            ----- su etiqueta es ----->     v

      ['n', 'psd'], ['dó', '1.cpl'], ['phu̱di', 'stem']      <----- morfologia de la palabra -------
  """


  """## Feature functions: corpus"""

  """
  Feature function only take the phrase, where the phrase has words and its tags
  """
  def feature(corpus):
    cps = []
    for phrase in corpus:
      cps.append(phrase_to_corpus_elmt(phrase))
    return cps

  """
  Take a phrase and converts all of its elements to just the words and its tags

  [['n', 'psd'], ['dó', '1.cpl'], ['phu̱di', 'stem'], 'v']         -> ["ndóphu̱di", "v"]
  [['bi', '3.cpl'], ['mähtratá', 'stem'], ['gí', '1.obj'], 'v']   -> ["bimähtratágí", v]
  """
  def phrase_to_corpus_elmt(phrase):
    lst = []
    for w_n_t in phrase:
      tag = w_n_t[-1] #tag
      raw_word = w_n_t[:-1]
      word = aux(raw_word)
      #print([word,tag])
      lst.append([word,tag])
    return lst

  """
  Take the parts of a word  and contats them

  [['n', 'psd'], ['dó', '1.cpl'], ['phu̱di', 'stem']] -> ["ndóphu̱di"]
  """
  def aux(raw_word):
    word = ""
    for part in raw_word:
      word += part[0]
    return word

  corpus = feature(raw_corpus)


  """## Feature functions 2: X, y

  Dividimos a los x de los y
  """

  def divide(corpus):
    X = []
    Y = []
    for phrase in corpus:
      x, y = divide_x_n_y(phrase)
      X.append(x)
      Y.append(y)
    return X, Y

  def divide_x_n_y(phrase):
    X = []
    Y = []
    for x_n_y in phrase:
      x = x_n_y[0]
      y = x_n_y[1]
      X.append(x)
      Y.append(y)
    return X, Y


  """#### Antes que nada, volvemos a codificar cada cadena de X"""

  X, Y = divide(corpus[:5])


  """Sí funcionó, ahora hagamoslo con todo el corpus:"""

  #pip install unidecode

  from unidecode import unidecode

  X, Y = divide(corpus)

  Y_1 = []
  for y in Y:
    phrase = []
    for word in y:
      word = unidecode(word)
      phrase.append(word)
    Y_1.append(phrase)

  y = Y_1

  """## Feature functions 3: final_corpus"""

  def word_to_features(sent, i):
      word = sent[i][0]
      features = {
          'word.lower()': word.lower(),
          'word[:3]': word[:3],
          'word[:2]': word[:2],
          'word.isupper()': word.isupper(),
          'word.istitle()': word.istitle(),
          'word.isdigit()': word.isdigit(),
          'len(word)': len(word),
          'postition': i,
      }
      if i > 0:
          prev_word = sent[i - 1][0]
          features.update({
              'prev_word.lower()': prev_word.lower(),
              'prev_word.istitle()': prev_word.istitle(),
          })
      else:
          features['BOS'] = True  # Beginning of sentence

      return features

  # Extract features and labels
  def sent_to_features(sent):
      return [word_to_features(sent, i) for i in range(len(sent))]

  def sent_to_labels(sent):
      return [label for token, label in sent]

  X = [[word_to_features(sent, i) for i in range(len(sent))] for sent in corpus]


  """## Entrenando modelo"""

  # Split the data into training and testing sets
  X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

  from inspect import Attribute
  from sklearn_crfsuite import CRF
  # Initialize and train the CRF tagger: https://sklearn-crfsuite.readthedocs.io/en/latest/api.html
  crf = CRF(algorithm='lbfgs', c1=0.1, c2=0.1, max_iterations=400, all_possible_transitions=True, verbose=True)
  try:
      crf.fit(X_train, y_train)
  except AttributeError as e:
      print(e)

  """## Metricas generales"""

  from sklearn.metrics import classification_report
  y_pred = crf.predict(X_test) #los datos que predijo

  """
    Tratando los datos de "y": los verdaderos y los predecidos
  """
  # Flatten the true and predicted labels
  y_test_flat = [label for sent_labels in y_test for label in sent_labels] #verdaderos
  y_pred_flat = [label for sent_labels in y_pred for label in sent_labels] #predecidos




  print("################################# METRICAS #################################")

  # Evaluate the model
  report = classification_report(y_true=y_test_flat, y_pred=y_pred_flat)
  print(report)

  """## Metricas especificas

  #### Accuracy = $\frac{TP + TN}{TP + TN + FP + FN} = 0.9273709483793517$
  """
  print("####################\nAccuracy")
  from sklearn.metrics import accuracy_score
  print(accuracy_score(y_pred_flat, y_test_flat))


  """#### Precision = $\frac{TP}{TP + FP} = 0.7320548193546926$"""
  print("####################\nPrecision")
  from sklearn.metrics import precision_score
  print(precision_score(y_pred_flat, y_test_flat, average="macro"))


  """#### Recall = $\frac{TP}{TP + FN} = 0.7320867433131187
  $
  """
  print("####################\nRecall")
  from sklearn.metrics import recall_score
  print(recall_score(y_pred_flat, y_test_flat, average="macro"))


  """#### F1-score = $\frac{2PR}{P + R} = 0.7300134993972263$"""
  print("####################\nF1-score")
  from sklearn.metrics import f1_score
  print(f1_score(y_pred_flat, y_test_flat, average="macro"))

  print("\n\n\n#################### Ejemplo oracion etiquetada (Oracion del conjunto de pruebas) ####################")
  sentence = X_test[0]
  string = " ".join([w['word.lower()'] for w in sentence])
  print(f"\nOración: {string}")
  prediction = crf.predict([sentence])
  print(f"\nEtiquetado obtenido (Y-predict): {', '.join(prediction[0])}")
  print(f"\nEtiquetado correcto (Y-test): {', '.join(y_test[0])}")