{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "cOGIZKXYeP4Z",
      "metadata": {
        "id": "cOGIZKXYeP4Z"
      },
      "source": [
        "## - Jean Durán Villanueva\n",
        "##- 316032416\n",
        "##- jean.dv@ciencias.unam.mx"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c-Q91_zR859L",
      "metadata": {
        "id": "c-Q91_zR859L"
      },
      "source": [
        "## Funciones tomadas del notebook \"1_phonetics\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "id": "dfCkH58988vq",
      "metadata": {
        "id": "dfCkH58988vq"
      },
      "outputs": [],
      "source": [
        "import requests as r\n",
        "\n",
        "response = r.get(\"https://raw.githubusercontent.com/open-dict-data/ipa-dict/master/data/en_US.txt\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cJMkPF06jJJp",
      "metadata": {
        "id": "cJMkPF06jJJp"
      },
      "source": [
        "### Obteniendo el corpus"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "id": "YSRb9cx5jM8d",
      "metadata": {
        "id": "YSRb9cx5jM8d"
      },
      "outputs": [],
      "source": [
        "lang_codes = {\n",
        "  \"ar\": \"Arabic (Modern Standard)\",\n",
        "  \"de\": \"German\",\n",
        "  \"en_UK\": \"English (Received Pronunciation)\",\n",
        "  \"en_US\": \"English (General American)\",\n",
        "  \"eo\": \"Esperanto\",\n",
        "  \"es_ES\": \"Spanish (Spain)\",\n",
        "  \"es_MX\": \"Spanish (Mexico)\",\n",
        "  \"fa\": \"Persian\",\n",
        "  \"fi\": \"Finnish\",\n",
        "  \"fr_FR\": \"French (France)\",\n",
        "  \"fr_QC\": \"French (Québec)\",\n",
        "  \"is\": \"Icelandic\",\n",
        "  \"ja\": \"Japanese\",\n",
        "  \"jam\": \"Jamaican Creole\",\n",
        "  \"km\": \"Khmer\",\n",
        "  \"ko\": \"Korean\",\n",
        "  \"ma\": \"Malay (Malaysian and Indonesian)\",\n",
        "  \"nb\": \"Norwegian Bokmål\",\n",
        "  \"nl\": \"Dutch\",\n",
        "  \"or\": \"Odia\",\n",
        "  \"ro\": \"Romanian\",\n",
        "  \"sv\": \"Swedish\",\n",
        "  \"sw\": \"Swahili\",\n",
        "  \"tts\": \"Isan\",\n",
        "  \"vi_C\": \"Vietnamese (Central)\",\n",
        "  \"vi_N\": \"Vietnamese (Northern)\",\n",
        "  \"vi_S\": \"Vietnamese (Southern)\",\n",
        "  \"yue\": \"Cantonese\",\n",
        "  \"zh\": \"Mandarin\"\n",
        "}\n",
        "iso_lang_codes = list(lang_codes.keys())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "id": "3vfeGyqYkI9V",
      "metadata": {
        "id": "3vfeGyqYkI9V"
      },
      "outputs": [],
      "source": [
        "def response_to_dict(ipa_list: list) -> dict:\n",
        "    \"\"\"Parse to dict the list of word-IPA\n",
        "\n",
        "    Each element of text hae the format:\n",
        "    [WORD][TAB][IPA]\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    ipa_list: list\n",
        "        List with each row of ipa-dict raw dataset file\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    dict:\n",
        "        A dictionary with the word as key and the phonetic\n",
        "        representation as value\n",
        "    \"\"\"\n",
        "    result = {}\n",
        "    for item in ipa_list:\n",
        "        item_list = item.split(\"\\t\")\n",
        "        result[item_list[0]] = item_list[1]\n",
        "    return result\n",
        "\n",
        "def get_ipa_dict(iso_lang: str) -> dict:\n",
        "    \"\"\"Get ipa-dict file from Github\n",
        "\n",
        "    Parameters:\n",
        "    -----------\n",
        "    iso_lang:\n",
        "        Language as iso code\n",
        "\n",
        "    Results:\n",
        "    --------\n",
        "    dict:\n",
        "        Dictionary with words as keys and phonetic representation\n",
        "        as values for a given lang code\n",
        "    \"\"\"\n",
        "    response = r.get(f\"https://raw.githubusercontent.com/open-dict-data/ipa-dict/master/data/{iso_lang}.txt\")\n",
        "    raw_data = response.text.split(\"\\n\")\n",
        "    return response_to_dict(raw_data[:-1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "id": "hT6xl-qAVBkO",
      "metadata": {
        "id": "hT6xl-qAVBkO"
      },
      "outputs": [],
      "source": [
        "from collections import defaultdict\n",
        "lang = \"es_MX\""
      ]
    },
    {
      "cell_type": "markdown",
      "id": "s63vQqcSuOAR",
      "metadata": {
        "id": "s63vQqcSuOAR"
      },
      "source": [
        "# Práctica"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "vb3nzqCNuwwP",
      "metadata": {
        "id": "vb3nzqCNuwwP"
      },
      "source": [
        "## Agregar un nuevo modo de búsqueda donde se extienda el comportamiento básico del buscador para ahora buscar por frases. Ejemplo:\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "```\n",
        "[es_MX]>>> Hola que hace\n",
        " /ola/ /ke/ /ase/\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "rIhAdhAnEaAg",
      "metadata": {
        "id": "rIhAdhAnEaAg"
      },
      "source": [
        "Hecho ✅. Resultado en la funcion \"f\" al final de este notebook"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "RWwbeEN293hq",
      "metadata": {
        "id": "RWwbeEN293hq"
      },
      "source": [
        "## Optimizar el código para agregar los datasets en un \"cache\" a demanda y no descargar todo el corpus de un trancazo. Esto quiere decir que al inicio de la ejecución no habrá ningun dataset descargado. Mientras la usuaria vaya seleccionado idiomas los irá agregando a un cache local (puede ser persistente o en memoria). Ejemplo:\n",
        "\n",
        "```\n",
        "lang>> es_MX\n",
        "Corpus no encontrado. Descargando ...\n",
        "[es_MX]>>\n",
        "...\n",
        "lang>> en_US\n",
        "Corpus no encontrado. Descargando ...\n",
        "[en_US]>>\n",
        "...\n",
        "lang>> es_MX\n",
        "[es_MX]>>\n",
        "...\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "HhqNMn4sKV96",
      "metadata": {
        "id": "HhqNMn4sKV96"
      },
      "source": [
        "### Esta funcion se encarga de agregar un lenguaje a la vez.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "id": "APh1emt6Hm6j",
      "metadata": {
        "id": "APh1emt6Hm6j"
      },
      "outputs": [],
      "source": [
        "import requests as r\n",
        "response = r.get(\"https://raw.githubusercontent.com/open-dict-data/ipa-dict/master/data/en_US.txt\")\n",
        "\n",
        "def get_lang(dict, iso_lang):\n",
        "    \"\"\"Agrega un nuevo idioma a nuestro dataset\n",
        "\n",
        "    dict\n",
        "      el diccionario al que agregamos un nuevo lenguaje\n",
        "\n",
        "    iso_lang\n",
        "      aque iso que agregaremos\n",
        "    \"\"\"\n",
        "    leng = get_ipa_dict(iso_lang)\n",
        "\n",
        "    if leng == {}:\n",
        "      #print(\"El idioma que buscas no existe\")\n",
        "      return False\n",
        "    else:\n",
        "      dict[iso_lang] = leng\n",
        "      return dict"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9IkOFgXnlLep",
      "metadata": {
        "id": "9IkOFgXnlLep"
      },
      "source": [
        "## EXTRA\n",
        "\n",
        "- Mejorar la solución al escenario cuando no se encuentran las palabras en el dataset mostrando palabras similares. Ejemplo:\n",
        "\n",
        "```\n",
        "[es_MX]>> pero\n",
        "No se encontro <<pero>> en el dataset. Palabras aproximadas:\n",
        "perro /pero/\n",
        "perno /peɾno/\n",
        "[es_MX]>>\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "xu8DLNFytK1m",
      "metadata": {
        "id": "xu8DLNFytK1m"
      },
      "source": [
        "##  💻💻💻💻💻💻Código 💻💻💻💻💻💻\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "MqAVkbDOZMDL",
      "metadata": {
        "id": "MqAVkbDOZMDL"
      },
      "source": [
        "### \"get_ipa_transcriptions\"\n",
        "\n",
        "- Toma una palabra y un lenguaje. Regresa el ipa de esta\n",
        "- Inspirada en la funcion \"get_ipa_transcriptions\" del notebook \"1_phonetics\"\n",
        "- La diferencia radica en que esta funcion regresa una subcadena que sea parte del lenguaje\n",
        "  - En caso de no encontrar a la cadena, claro.\n",
        "  - Las subcadenas que busca son del estilo: si no encuentra computadorabcd, entonces computadorabc, computadorab, y regresa computadora\n",
        "    - Esto lo hace hasta la mitad de la longitud de la cadena. Si osoabc, entonces busca hasta oso\n",
        "- Está preparada además para regresar un mensaje en caso de no haber encontrado una subcadena"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "id": "7vyKbjBPXnnM",
      "metadata": {
        "id": "7vyKbjBPXnnM"
      },
      "outputs": [],
      "source": [
        "def get_ipa_transcriptions(word: str, sub_dict: dict) -> list[str]:\n",
        "  word.lower()\n",
        "  try:\n",
        "    return (sub_dict[word]).split(\", \") #1a. salida. Todo igual\n",
        "  except:\n",
        "    #aviso = \"NOT FOUND. Here it is some words related. Lets try with a subchain.\"\n",
        "    l = int(len(word)/2)\n",
        "    for i in range(1,l):\n",
        "      try:\n",
        "        result = sub_dict[word[:-i]]\n",
        "        word = word[:-i]\n",
        "        return (True,result.split(\", \"),word) #2a salida. Cuando encontro sub cadena.\n",
        "      except:\n",
        "        pass\n",
        "  aviso2 = \"NOT FOUND. Let's try with near subchains...      Near subchains NOT FOUNDED\"\n",
        "  return (False,aviso2) #3a salida. Cuando no encontro subcadena"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b-08MDDFZn6_",
      "metadata": {
        "id": "b-08MDDFZn6_"
      },
      "source": [
        "### \"phrase_to_ipa\"\n",
        "\n",
        "- Se encarga de mostrar los resultados de cada frase que se escribe en un mismo idioma, hasta que se salga de esta funcion\n",
        "- Pide la frase al usuario y llama mediante un for a \"get_ipa_transcriptions\" con el lenguaje y cada palabra.\n",
        "  - Se guardan los resultados y se despliegan mediante un for (un poco ineficiente ahora que lo pienso, jeje).\n",
        "    - Dependiendo si se encontro la cadena, se encontro una subcadena o no se despliegan los mensahes  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "id": "x_h4Lrb9Zaq2",
      "metadata": {
        "id": "x_h4Lrb9Zaq2"
      },
      "outputs": [],
      "source": [
        "def phrase_to_ipa(sub_dict):\n",
        "  query = input(f\"\\n  phrase>> \")\n",
        "  query = query.split(\" \")\n",
        "  results = [get_ipa_transcriptions(q, sub_dict) for q in query]\n",
        "  for q,r in zip(query, results):\n",
        "    if not isinstance(r, tuple):\n",
        "      print(\"  <<<<<<<<>>>>>>>>>\")\n",
        "      print(\"  \",q, \" | \", \", \".join(r)) #word exists\n",
        "    else:\n",
        "      if r[0]:\n",
        "        print(\"  <<<<<<<<word not found, but subchain of word>>>>>>>>>\")\n",
        "        print(\"  \",r[2], \" | \", \", \".join(r[1])) #subchain of word exists\n",
        "      else:\n",
        "        print(\"  <<<<<<<<>>>>>>>>>\")\n",
        "        print(\"  \",q, \" | \",r[1]) #subchain of word doesnt exists\n",
        "\n",
        "\n",
        "  while query:\n",
        "    sub_dict\n",
        "    query = input(f\"\\n  phrase>> \")\n",
        "    if query == \"\":\n",
        "      print(\"\\n\")\n",
        "      break\n",
        "    query = query.split(\" \")\n",
        "    results = [get_ipa_transcriptions(q, sub_dict) for q in query]\n",
        "    for q,r in zip(query, results):\n",
        "      if not isinstance(r, tuple):\n",
        "        print(\"  <<<<<<<<>>>>>>>>>\")\n",
        "        print(\"  \",q, \" | \", \", \".join(r)) #word exists\n",
        "      else:\n",
        "        if r[0]:\n",
        "          print(\"  <<<<<<<<word not found, but subchain of word>>>>>>>>>\")\n",
        "          print(\"  \",r[2], \" | \", \", \".join(r[1])) #subchain of word exists\n",
        "        else:\n",
        "          print(\"  <<<<<<<<>>>>>>>>>\")\n",
        "          print(\"  \",q, \" | \",r[1]) #subchain of word doesnt exists"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "DfLJjFwUZYUV",
      "metadata": {
        "id": "DfLJjFwUZYUV"
      },
      "source": [
        "### Funcion f, que cumple los 3 puntos de la practica\n",
        "\n",
        "- Acepta frases, i.e., más de una cadena\n",
        "- Agrega los lenguajes a demanda, ie,\n",
        "  - No precarga ellos sino que los descarga si no lo tiene y lo mantiene incluso si se vuelve a ejecutar la funcion \"f\"\n",
        "- Si no encuentra la cadena, sugiere subcadenas de esta.\n",
        "  - Muestra la primer subcadena que encuentre y si no la encuentra, muestra un mensaje indicandolo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "id": "5WRjjJ3zZi8f",
      "metadata": {
        "id": "5WRjjJ3zZi8f"
      },
      "outputs": [],
      "source": [
        "def f(dict):\n",
        "  print(\"Representación fonética de palabras\")\n",
        "\n",
        "  print(f\"Lenguas disponibles: {(iso_lang_codes)} \\n \\n \\n\")\n",
        "\n",
        "  iso = \" \"\n",
        "  while iso:\n",
        "    iso = input(\"lang>> \")\n",
        "    if iso == \"\":\n",
        "      print(\"Bye bye 👋🏼\")\n",
        "      break\n",
        "\n",
        "    try:\n",
        "      sub_dict = dict[iso]\n",
        "      #proceso de escribir la frase\n",
        "      phrase_to_ipa(sub_dict)\n",
        "    except:\n",
        "      print(\"El idioma no se encuentra de manera local. Consultandola...\")\n",
        "      result = get_lang(dict, iso)\n",
        "      if not result:\n",
        "        print(\"No se encuentra el iso <\",iso,\"> que ingresas. Intenta con otro\")\n",
        "      else:\n",
        "        print(\"Encontrado y guardado!\")\n",
        "        #proceso de escribir la frase\n",
        "        sub_dict = dict[iso]\n",
        "        phrase_to_ipa(sub_dict)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "_9wqUbwSPqgT",
      "metadata": {
        "id": "_9wqUbwSPqgT"
      },
      "source": [
        "Declarar el diccionario \"dict\" por separado permite que se cuando se vuelva a ejecutar la funcion \"f(dict)\" en el futuro, los idiomas se queden guardados. (Todo esto mientras dict no se iguale a el diccionario vacío)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 74,
      "id": "F8aU8ySvPepf",
      "metadata": {
        "id": "F8aU8ySvPepf"
      },
      "outputs": [],
      "source": [
        "dict = {}"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4INiYj5fQOrf",
      "metadata": {
        "id": "4INiYj5fQOrf"
      },
      "source": [
        "Para probar todo el codigo anterior, basta con ejecutar la siguiente linea de código"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 75,
      "id": "4RVovf21c9fh",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4RVovf21c9fh",
        "outputId": "5dc08756-fc63-4d78-97eb-01c9f6cea4cd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Representación fonética de palabras\n",
            "Lenguas disponibles: ['ar', 'de', 'en_UK', 'en_US', 'eo', 'es_ES', 'es_MX', 'fa', 'fi', 'fr_FR', 'fr_QC', 'is', 'ja', 'jam', 'km', 'ko', 'ma', 'nb', 'nl', 'or', 'ro', 'sv', 'sw', 'tts', 'vi_C', 'vi_N', 'vi_S', 'yue', 'zh'] \n",
            " \n",
            " \n",
            "\n",
            "lang>> fr_\n",
            "El idioma no se encuentra de manera local. Consultandola...\n",
            "No se encuentra el iso < fr_ > que ingresas. Intenta con otro\n",
            "lang>> fr_FR\n",
            "El idioma no se encuentra de manera local. Consultandola...\n",
            "Encontrado y guardado!\n",
            "\n",
            "  phrase>> j'aime tes genoux\n",
            "  <<<<<<<<word not found, but subchain of word>>>>>>>>>\n",
            "   j'ai  |  /ʒe/\n",
            "  <<<<<<<<>>>>>>>>>\n",
            "   tes  |  /te/\n",
            "  <<<<<<<<>>>>>>>>>\n",
            "   genoux  |  /ʒənu/\n",
            "\n",
            "  phrase>> paris\n",
            "  <<<<<<<<>>>>>>>>>\n",
            "   paris  |  /paʁi/\n",
            "\n",
            "  phrase>> \n",
            "\n",
            "\n",
            "lang>> es_MX\n",
            "El idioma no se encuentra de manera local. Consultandola...\n",
            "Encontrado y guardado!\n",
            "\n",
            "  phrase>> viva la vida\n",
            "  <<<<<<<<>>>>>>>>>\n",
            "   viva  |  /biβa/\n",
            "  <<<<<<<<>>>>>>>>>\n",
            "   la  |  /la/\n",
            "  <<<<<<<<>>>>>>>>>\n",
            "   vida  |  /biða/\n",
            "\n",
            "  phrase>> ya tengo 10 es pregunta\n",
            "  <<<<<<<<>>>>>>>>>\n",
            "   ya  |  /ʝa/\n",
            "  <<<<<<<<>>>>>>>>>\n",
            "   tengo  |  /teŋgo/\n",
            "  <<<<<<<<>>>>>>>>>\n",
            "   10  |  NOT FOUND. Let's try with near subchains...      Near subchains NOT FOUNDED\n",
            "  <<<<<<<<>>>>>>>>>\n",
            "   es  |  /es/\n",
            "  <<<<<<<<>>>>>>>>>\n",
            "   pregunta  |  /pɾeɣunta/\n",
            "\n",
            "  phrase>> \n",
            "\n",
            "\n",
            "lang>> \n",
            "Bye bye 👋🏼\n"
          ]
        }
      ],
      "source": [
        "f(dict)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "c-Q91_zR859L",
        "vb3nzqCNuwwP",
        "RWwbeEN293hq",
        "HhqNMn4sKV96",
        "MqAVkbDOZMDL",
        "b-08MDDFZn6_"
      ],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
